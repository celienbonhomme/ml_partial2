{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset, already processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWind = pd.read_csv('../data/data_wind_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hora</th>\n",
       "      <th>Dirección del viento horaria (gr)</th>\n",
       "      <th>Velocidad horario del viento (m/s)</th>\n",
       "      <th>Máxima ráfaga de viento (m/s)</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Humedad rel. máx. hora anterior (AUT)</th>\n",
       "      <th>Humedad rel. mín. hora anterior (AUT)</th>\n",
       "      <th>Temperatura máx. hora anterior (AUT) (K)</th>\n",
       "      <th>Temperatura mín. hora anterior (AUT) (K)</th>\n",
       "      <th>Humedad relativa horaria</th>\n",
       "      <th>Presión atmosférica a nivel de estación, horaria (Pa)</th>\n",
       "      <th>Precipitación total por hora (m)</th>\n",
       "      <th>Presión atmosférica máx. hora anterior (AUT) (Pa)</th>\n",
       "      <th>Presión atmosférica mín. hora anterior (AUT) (Pa)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2000-01-01 12:00:00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>295.75</td>\n",
       "      <td>293.85</td>\n",
       "      <td>0.61</td>\n",
       "      <td>88820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88820.0</td>\n",
       "      <td>88770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2000-01-01 13:00:00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.55</td>\n",
       "      <td>297.35</td>\n",
       "      <td>295.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>88840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88840.0</td>\n",
       "      <td>88820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.891007</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2000-01-01 14:00:00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>298.65</td>\n",
       "      <td>297.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>88810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88840.0</td>\n",
       "      <td>88810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.848048</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2000-01-01 15:00:00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>300.55</td>\n",
       "      <td>298.15</td>\n",
       "      <td>0.44</td>\n",
       "      <td>88740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88810.0</td>\n",
       "      <td>88740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.224951</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2000-01-01 16:00:00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>300.25</td>\n",
       "      <td>298.65</td>\n",
       "      <td>0.46</td>\n",
       "      <td>88650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88740.0</td>\n",
       "      <td>88650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hora  Dirección del viento horaria (gr)  \\\n",
       "0    12                           0.809017   \n",
       "1    13                           0.965926   \n",
       "2    14                           0.891007   \n",
       "3    15                           0.848048   \n",
       "4    16                           0.224951   \n",
       "\n",
       "   Velocidad horario del viento (m/s)  Máxima ráfaga de viento (m/s)  \\\n",
       "0                                 1.8                            3.8   \n",
       "1                                 2.7                            4.7   \n",
       "2                                 2.0                            4.9   \n",
       "3                                 2.5                            5.8   \n",
       "4                                 2.4                            5.8   \n",
       "\n",
       "                 Fecha  Humedad rel. máx. hora anterior (AUT)  \\\n",
       "0  2000-01-01 12:00:00                                   0.69   \n",
       "1  2000-01-01 13:00:00                                   0.62   \n",
       "2  2000-01-01 14:00:00                                   0.56   \n",
       "3  2000-01-01 15:00:00                                   0.52   \n",
       "4  2000-01-01 16:00:00                                   0.50   \n",
       "\n",
       "   Humedad rel. mín. hora anterior (AUT)  \\\n",
       "0                                   0.60   \n",
       "1                                   0.55   \n",
       "2                                   0.50   \n",
       "3                                   0.44   \n",
       "4                                   0.43   \n",
       "\n",
       "   Temperatura máx. hora anterior (AUT) (K)  \\\n",
       "0                                    295.75   \n",
       "1                                    297.35   \n",
       "2                                    298.65   \n",
       "3                                    300.55   \n",
       "4                                    300.25   \n",
       "\n",
       "   Temperatura mín. hora anterior (AUT) (K)  Humedad relativa horaria  \\\n",
       "0                                    293.85                      0.61   \n",
       "1                                    295.65                      0.55   \n",
       "2                                    297.45                      0.51   \n",
       "3                                    298.15                      0.44   \n",
       "4                                    298.65                      0.46   \n",
       "\n",
       "   Presión atmosférica a nivel de estación, horaria (Pa)  \\\n",
       "0                                            88820.0       \n",
       "1                                            88840.0       \n",
       "2                                            88810.0       \n",
       "3                                            88740.0       \n",
       "4                                            88650.0       \n",
       "\n",
       "   Precipitación total por hora (m)  \\\n",
       "0                               0.0   \n",
       "1                               0.0   \n",
       "2                               0.0   \n",
       "3                               0.0   \n",
       "4                               0.0   \n",
       "\n",
       "   Presión atmosférica máx. hora anterior (AUT) (Pa)  \\\n",
       "0                                            88820.0   \n",
       "1                                            88840.0   \n",
       "2                                            88840.0   \n",
       "3                                            88810.0   \n",
       "4                                            88740.0   \n",
       "\n",
       "   Presión atmosférica mín. hora anterior (AUT) (Pa)  \n",
       "0                                            88770.0  \n",
       "1                                            88820.0  \n",
       "2                                            88810.0  \n",
       "3                                            88740.0  \n",
       "4                                            88650.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90276"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWind.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models and their parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bayesan Ridge': {'model': BayesianRidge(),\n",
       "  'grid': {'model__alpha_1': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]},\n",
       "  'MAPE_score': [],\n",
       "  'R2_score': [],\n",
       "  'RMSE_score': []},\n",
       " 'Decision Tree': {'model': DecisionTreeRegressor(random_state=42),\n",
       "  'grid': {'model__max_depth': (1, 20),\n",
       "   'model__min_samples_split': (0.1, 1.0)},\n",
       "  'MAPE_score': [],\n",
       "  'R2_score': [],\n",
       "  'RMSE_score': []},\n",
       " 'Random Forest': {'model': RandomForestRegressor(random_state=42),\n",
       "  'grid': {'model__max_depth': (1, 20),\n",
       "   'model__n_estimators': [100, 200, 300]},\n",
       "  'n_estimators': range(1, 20),\n",
       "  'MAPE_score': [],\n",
       "  'R2_score': [],\n",
       "  'RMSE_score': []},\n",
       " 'Gradient Boosting': {'model': GradientBoostingRegressor(random_state=42),\n",
       "  'grid': {'model__max_depth': (1, 20),\n",
       "   'model__min_samples_split': (0.1, 1.0)},\n",
       "  'MAPE_score': [],\n",
       "  'R2_score': [],\n",
       "  'RMSE_score': []},\n",
       " 'Knn': {'model': KNeighborsRegressor(),\n",
       "  'grid': {'model__n_neighbors': (1, 20)},\n",
       "  'MAPE_score': [],\n",
       "  'R2_score': [],\n",
       "  'RMSE_score': []},\n",
       " 'Ridge': {'model': Ridge(),\n",
       "  'grid': {'model__alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "  'MAPE_score': [],\n",
       "  'R2_score': [],\n",
       "  'RMSE_score': []},\n",
       " 'Lasso': {'model': Lasso(),\n",
       "  'grid': {'model__alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
       "  'MAPE_score': [],\n",
       "  'R2_score': [],\n",
       "  'RMSE_score': []}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import linear_model\n",
    "\n",
    "grid_nb = {}\n",
    "\n",
    "model_dict = {}\n",
    "\n",
    "model_dict['Bayesan Ridge'] = {'model': linear_model.BayesianRidge(), 'grid': {'model__alpha_1': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1]}, 'MAPE_score': {}, 'R2_score': {}, 'RMSE_score': {}}\n",
    "model_dict['Decision Tree'] = {'model': DecisionTreeRegressor(random_state=42), 'grid': {'model__max_depth': (1, 20),'model__min_samples_split' : (0.1,1.0)}, 'MAPE_score': {}, 'R2_score': {}, 'RMSE_score': {}}\n",
    "model_dict['Random Forest'] = {'model': RandomForestRegressor(random_state=42), 'grid': {'model__max_depth': (1, 20),'model__n_estimators': [100, 200, 300]}, 'n_estimators': range(1, 20), 'MAPE_score': {}, 'R2_score': {}, 'RMSE_score': {}}\n",
    "model_dict['Gradient Boosting'] = {'model': GradientBoostingRegressor(random_state=42), 'grid': {'model__max_depth': (1, 20) ,'model__min_samples_split' : (0.1,1.0)}, 'MAPE_score': {}, 'R2_score': {}, 'RMSE_score': {}}\n",
    "model_dict['Knn'] = {'model': KNeighborsRegressor(), 'grid': {'model__n_neighbors': (1, 20)}, 'MAPE_score': {}, 'R2_score': {}, 'RMSE_score': {}}\n",
    "model_dict['Ridge'] = {'model': Ridge(), 'grid': {'model__alpha': [0.001,0.01,0.1,1,10,100,1000]}, 'MAPE_score': {}, 'R2_score': {}, 'RMSE_score': {}}\n",
    "model_dict['Lasso'] = {'model': Lasso(), 'grid': {'model__alpha': [0.001,0.01,0.1,1,10,100,1000]}, 'MAPE_score': {}, 'R2_score': {}, 'RMSE_score': {}}\n",
    "for model_name, model_info in model_dict.items():\n",
    "    model_info['MAPE_score'] = []\n",
    "    model_info['R2_score'] = []\n",
    "    model_info['RMSE_score'] = []\n",
    "cv = 10\n",
    "\n",
    "number_of_days = [7,14,21,28]\n",
    "\n",
    "model_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I instantiated a dictionary of models containg their parameters and their future scores so that it will be easier to manage them later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 14, 21, 28]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hora</th>\n",
       "      <th>Dirección del viento horaria (gr)</th>\n",
       "      <th>Velocidad horario del viento (m/s)</th>\n",
       "      <th>Máxima ráfaga de viento (m/s)</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Humedad rel. máx. hora anterior (AUT)</th>\n",
       "      <th>Humedad rel. mín. hora anterior (AUT)</th>\n",
       "      <th>Temperatura máx. hora anterior (AUT) (K)</th>\n",
       "      <th>Temperatura mín. hora anterior (AUT) (K)</th>\n",
       "      <th>Humedad relativa horaria</th>\n",
       "      <th>Presión atmosférica a nivel de estación, horaria (Pa)</th>\n",
       "      <th>Precipitación total por hora (m)</th>\n",
       "      <th>Presión atmosférica máx. hora anterior (AUT) (Pa)</th>\n",
       "      <th>Presión atmosférica mín. hora anterior (AUT) (Pa)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>0.809017</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2000-01-01 12:00:00</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>295.75</td>\n",
       "      <td>293.85</td>\n",
       "      <td>0.61</td>\n",
       "      <td>88820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88820.0</td>\n",
       "      <td>88770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2000-01-01 13:00:00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.55</td>\n",
       "      <td>297.35</td>\n",
       "      <td>295.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>88840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88840.0</td>\n",
       "      <td>88820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.891007</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2000-01-01 14:00:00</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>298.65</td>\n",
       "      <td>297.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>88810.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88840.0</td>\n",
       "      <td>88810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.848048</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2000-01-01 15:00:00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>300.55</td>\n",
       "      <td>298.15</td>\n",
       "      <td>0.44</td>\n",
       "      <td>88740.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88810.0</td>\n",
       "      <td>88740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.224951</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2000-01-01 16:00:00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.43</td>\n",
       "      <td>300.25</td>\n",
       "      <td>298.65</td>\n",
       "      <td>0.46</td>\n",
       "      <td>88650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88740.0</td>\n",
       "      <td>88650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hora  Dirección del viento horaria (gr)  \\\n",
       "0    12                           0.809017   \n",
       "1    13                           0.965926   \n",
       "2    14                           0.891007   \n",
       "3    15                           0.848048   \n",
       "4    16                           0.224951   \n",
       "\n",
       "   Velocidad horario del viento (m/s)  Máxima ráfaga de viento (m/s)  \\\n",
       "0                                 1.8                            3.8   \n",
       "1                                 2.7                            4.7   \n",
       "2                                 2.0                            4.9   \n",
       "3                                 2.5                            5.8   \n",
       "4                                 2.4                            5.8   \n",
       "\n",
       "                 Fecha  Humedad rel. máx. hora anterior (AUT)  \\\n",
       "0  2000-01-01 12:00:00                                   0.69   \n",
       "1  2000-01-01 13:00:00                                   0.62   \n",
       "2  2000-01-01 14:00:00                                   0.56   \n",
       "3  2000-01-01 15:00:00                                   0.52   \n",
       "4  2000-01-01 16:00:00                                   0.50   \n",
       "\n",
       "   Humedad rel. mín. hora anterior (AUT)  \\\n",
       "0                                   0.60   \n",
       "1                                   0.55   \n",
       "2                                   0.50   \n",
       "3                                   0.44   \n",
       "4                                   0.43   \n",
       "\n",
       "   Temperatura máx. hora anterior (AUT) (K)  \\\n",
       "0                                    295.75   \n",
       "1                                    297.35   \n",
       "2                                    298.65   \n",
       "3                                    300.55   \n",
       "4                                    300.25   \n",
       "\n",
       "   Temperatura mín. hora anterior (AUT) (K)  Humedad relativa horaria  \\\n",
       "0                                    293.85                      0.61   \n",
       "1                                    295.65                      0.55   \n",
       "2                                    297.45                      0.51   \n",
       "3                                    298.15                      0.44   \n",
       "4                                    298.65                      0.46   \n",
       "\n",
       "   Presión atmosférica a nivel de estación, horaria (Pa)  \\\n",
       "0                                            88820.0       \n",
       "1                                            88840.0       \n",
       "2                                            88810.0       \n",
       "3                                            88740.0       \n",
       "4                                            88650.0       \n",
       "\n",
       "   Precipitación total por hora (m)  \\\n",
       "0                               0.0   \n",
       "1                               0.0   \n",
       "2                               0.0   \n",
       "3                               0.0   \n",
       "4                               0.0   \n",
       "\n",
       "   Presión atmosférica máx. hora anterior (AUT) (Pa)  \\\n",
       "0                                            88820.0   \n",
       "1                                            88840.0   \n",
       "2                                            88840.0   \n",
       "3                                            88810.0   \n",
       "4                                            88740.0   \n",
       "\n",
       "   Presión atmosférica mín. hora anterior (AUT) (Pa)  \n",
       "0                                            88770.0  \n",
       "1                                            88820.0  \n",
       "2                                            88810.0  \n",
       "3                                            88740.0  \n",
       "4                                            88650.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfWind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning models and training them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BayesSearchCV i tune the models by searching for the best paramaters with bayesan optimization, this chunk of code takes every model out of the dictionary and finds the best hyperparameters for every possible scenario (in this case the number of days), so that we get the best parameters for every possible way of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m search_cv \u001b[38;5;241m=\u001b[39m BayesSearchCV(pipeline, param, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Fit the BayesSearchCV object to find the best parameters\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43msearch_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Store the best parameters for the current model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m best_params[model]\u001b[38;5;241m.\u001b[39mappend(search_cv\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/skopt/searchcv.py:538\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[0;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m     )\n\u001b[0;32m--> 538\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/skopt/searchcv.py:595\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[0;32m--> 595\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/skopt/searchcv.py:441\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[0;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate n_jobs parameters and evaluate them in parallel.\"\"\"\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# get parameter values to evaluate\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[1;32m    444\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:464\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[0;34m(self, n_points, strategy)\u001b[0m\n\u001b[1;32m    462\u001b[0m         opt\u001b[38;5;241m.\u001b[39m_tell(x, (y_lie, t_lie))\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_lie\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_ \u001b[38;5;241m=\u001b[39m {(n_points, strategy): X}  \u001b[38;5;66;03m# cache_ the result\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/skopt/optimizer/optimizer.py:615\u001b[0m, in \u001b[0;36mOptimizer._tell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    614\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 615\u001b[0m     \u001b[43mest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext_xs_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_func \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgp_hedge\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgains_ \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m est\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mvstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_xs_))\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/skopt/learning/gaussian_process/gpr.py:203\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise:\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel \u001b[38;5;241m+\u001b[39m WhiteKernel(\n\u001b[1;32m    201\u001b[0m             noise_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise, noise_level_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfixed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         )\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;66;03m# The noise component of this kernel should be set to zero\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# while estimating K(X_test, X_test)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# http://www.gaussianprocess.org/gpml/chapters/RW2.pdf\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# Hence this hack\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1349\u001b[0m     )\n\u001b[1;32m   1350\u001b[0m ):\n\u001b[0;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:307\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(theta, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[1;32m    305\u001b[0m optima \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    306\u001b[0m     (\n\u001b[0;32m--> 307\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     )\n\u001b[1;32m    311\u001b[0m ]\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:656\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 656\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    664\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    621\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    627\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py:306\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m--> 306\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[1;32m    312\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/optimize.py:261\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    257\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:140\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/scipy/optimize/optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 68\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:297\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 297\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:577\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    576\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_\n\u001b[0;32m--> 577\u001b[0m     \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m \u001b[38;5;241m=\u001b[39m theta\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m    580\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:743\u001b[0m, in \u001b[0;36mKernelOperator.theta\u001b[0;34m(self, theta)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sets the (flattened, log-transformed) non-fixed hyperparameters.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \n\u001b[1;32m    737\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m    The non-fixed, log-transformed hyperparameters of the kernel\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    742\u001b[0m k1_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1\u001b[38;5;241m.\u001b[39mn_dims\n\u001b[0;32m--> 743\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m \u001b[38;5;241m=\u001b[39m theta[:k1_dims]\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk2\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta[k1_dims:]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:742\u001b[0m, in \u001b[0;36mKernelOperator.theta\u001b[0;34m(self, theta)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;129m@theta\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtheta\u001b[39m(\u001b[38;5;28mself\u001b[39m, theta):\n\u001b[1;32m    735\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the (flattened, log-transformed) non-fixed hyperparameters.\u001b[39;00m\n\u001b[1;32m    736\u001b[0m \n\u001b[1;32m    737\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;124;03m        The non-fixed, log-transformed hyperparameters of the kernel\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 742\u001b[0m     k1_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_dims\u001b[49m\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta[:k1_dims]\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk2\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta[k1_dims:]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:257\u001b[0m, in \u001b[0;36mKernel.n_dims\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mn_dims\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    256\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the number of non-fixed hyperparameters of the kernel.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:284\u001b[0m, in \u001b[0;36mKernel.theta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the (flattened, log-transformed) non-fixed hyperparameters.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03mNote that theta are typically the log-transformed values of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    The non-fixed, log-transformed hyperparameters of the kernel\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m theta \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 284\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hyperparameter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hyperparameter\u001b[38;5;241m.\u001b[39mfixed:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:182\u001b[0m, in \u001b[0;36mKernel.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\n\u001b[1;32m    181\u001b[0m init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated_original\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[0;32m--> 182\u001b[0m init_sign \u001b[38;5;241m=\u001b[39m \u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m args, varargs \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parameter \u001b[38;5;129;01min\u001b[39;00m init_sign\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/inspect.py:3113\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/inspect.py:2862\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/inspect.py:2325\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2323\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2324\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2330\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_venv/lib/python3.9/inspect.py:2172\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;66;03m# Parameter information.\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m func_code \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\n\u001b[0;32m-> 2172\u001b[0m pos_count \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_code\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_argcount\u001b[49m\n\u001b[1;32m   2173\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m func_code\u001b[38;5;241m.\u001b[39mco_varnames\n\u001b[1;32m   2174\u001b[0m posonly_count \u001b[38;5;241m=\u001b[39m func_code\u001b[38;5;241m.\u001b[39mco_posonlyargcount\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Create an empty dictionary to store the best parameters for each model\n",
    "best_params = {}\n",
    "\n",
    "for model in model_dict.keys():\n",
    "    best_params[model] = []\n",
    "# Iterate over the models and perform parameter search\n",
    "for numDays in number_of_days:\n",
    "    X_train = dfWind.iloc[0:numDays*24].drop(['Velocidad horario del viento (m/s)', 'Fecha'], axis=1)\n",
    "    y_train = dfWind.iloc[0:numDays*24]['Velocidad horario del viento (m/s)']\n",
    "    for model in model_dict.keys():\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), ('model', model_dict[model]['model'])])\n",
    "        # Get the parameter search space for the current model\n",
    "        param = model_dict[model]['grid']\n",
    "        if len(param) == 0:\n",
    "            continue\n",
    "        # Create the BayesSearchCV object for the current model\n",
    "        search_cv = BayesSearchCV(pipeline, param, cv=5, n_iter=50, random_state=42)\n",
    "        \n",
    "        # Fit the BayesSearchCV object to find the best parameters\n",
    "        search_cv.fit(X_train, y_train)\n",
    "        \n",
    "        # Store the best parameters for the current model\n",
    "        best_params[model].append(search_cv.best_params_)\n",
    "        print(f\"Best parameters for {model} and with {numDays}: {search_cv.best_params_}\")\n",
    "\n",
    "# Print the best parameters for each model\n",
    "for model_name, params in best_params.items():\n",
    "    print(f\"Best parameters for {model_name}: {params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we can see every model has different best hyperparamaters for every scenario of validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train every model for each scenario, using (7,14,21,28) days as training dataset and the following day as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Training Decision Tree with 7 days...\n",
      "Decision Tree trained!\n",
      "MAPE: [80200798239406.03]\n",
      "R2: [0.362329532114189]\n",
      "RMSE: [0.5812604669144814]\n",
      "Training Decision Tree with 14 days...\n",
      "Decision Tree trained!\n",
      "MAPE: [80200798239406.03, 88711873783999.02]\n",
      "R2: [0.362329532114189, 0.47364411826624664]\n",
      "RMSE: [0.5812604669144814, 0.4817635708201701]\n",
      "Training Decision Tree with 21 days...\n",
      "Decision Tree trained!\n",
      "MAPE: [80200798239406.03, 88711873783999.02, 103043452094794.83]\n",
      "R2: [0.362329532114189, 0.47364411826624664, 0.4479596262008063]\n",
      "RMSE: [0.5812604669144814, 0.4817635708201701, 0.5004075012333904]\n",
      "Training Decision Tree with 28 days...\n",
      "Decision Tree trained!\n",
      "MAPE: [80200798239406.03, 88711873783999.02, 103043452094794.83, 72295978716041.75]\n",
      "R2: [0.362329532114189, 0.47364411826624664, 0.4479596262008063, 0.5034122717854398]\n",
      "RMSE: [0.5812604669144814, 0.4817635708201701, 0.5004075012333904, 0.4457925095100728]\n",
      "Training Random Forest...\n",
      "Training Random Forest with 7 days...\n",
      "Random Forest trained!\n",
      "MAPE: [81607234341902.56]\n",
      "R2: [0.5446504505277066]\n",
      "RMSE: [0.4217273773627547]\n",
      "Training Random Forest with 14 days...\n",
      "Random Forest trained!\n",
      "MAPE: [81607234341902.56, 73368485888530.53]\n",
      "R2: [0.5446504505277066, 0.5870522624137625]\n",
      "RMSE: [0.4217273773627547, 0.38262266359355546]\n",
      "Training Random Forest with 21 days...\n",
      "Random Forest trained!\n",
      "MAPE: [81607234341902.56, 73368485888530.53, 77910419980004.86]\n",
      "R2: [0.5446504505277066, 0.5870522624137625, 0.5645065018813064]\n",
      "RMSE: [0.4217273773627547, 0.38262266359355546, 0.3981726840078157]\n",
      "Training Random Forest with 28 days...\n",
      "Random Forest trained!\n",
      "MAPE: [81607234341902.56, 73368485888530.53, 77910419980004.86, 67906817030324.336]\n",
      "R2: [0.5446504505277066, 0.5870522624137625, 0.5645065018813064, 0.6072123010567742]\n",
      "RMSE: [0.4217273773627547, 0.38262266359355546, 0.3981726840078157, 0.36327904126460725]\n",
      "Training Gradient Boosting...\n",
      "Training Gradient Boosting with 7 days...\n",
      "Gradient Boosting trained!\n",
      "MAPE: [82003114542011.16]\n",
      "R2: [0.524809721228212]\n",
      "RMSE: [0.4411063483970683]\n",
      "Training Gradient Boosting with 14 days...\n",
      "Gradient Boosting trained!\n",
      "MAPE: [82003114542011.16, 85131749820761.67]\n",
      "R2: [0.524809721228212, 0.5773859178516063]\n",
      "RMSE: [0.4411063483970683, 0.3909666440258513]\n",
      "Training Gradient Boosting with 21 days...\n",
      "Gradient Boosting trained!\n",
      "MAPE: [82003114542011.16, 85131749820761.67, 84421806169916.22]\n",
      "R2: [0.524809721228212, 0.5773859178516063, 0.5910344481794995]\n",
      "RMSE: [0.4411063483970683, 0.3909666440258513, 0.3771596829807505]\n",
      "Training Gradient Boosting with 28 days...\n",
      "Gradient Boosting trained!\n",
      "MAPE: [82003114542011.16, 85131749820761.67, 84421806169916.22, 74488197785733.05]\n",
      "R2: [0.524809721228212, 0.5773859178516063, 0.5910344481794995, 0.6070234312123858]\n",
      "RMSE: [0.4411063483970683, 0.3909666440258513, 0.3771596829807505, 0.3630620006776562]\n",
      "Training Knn...\n",
      "Training Knn with 7 days...\n",
      "Knn trained!\n",
      "MAPE: [142360027014206.3]\n",
      "R2: [0.08283070051992217]\n",
      "RMSE: [0.8462401326368166]\n",
      "Training Knn with 14 days...\n",
      "Knn trained!\n",
      "MAPE: [142360027014206.3, 129573827181546.03]\n",
      "R2: [0.08283070051992217, 0.23456601106785016]\n",
      "RMSE: [0.8462401326368166, 0.704619547738372]\n",
      "Training Knn with 21 days...\n",
      "Knn trained!\n",
      "MAPE: [142360027014206.3, 129573827181546.03, 117461717368969.97]\n",
      "R2: [0.08283070051992217, 0.23456601106785016, 0.33346870100809894]\n",
      "RMSE: [0.8462401326368166, 0.704619547738372, 0.6110292735429359]\n",
      "Training Knn with 28 days...\n",
      "Knn trained!\n",
      "MAPE: [142360027014206.3, 129573827181546.03, 117461717368969.97, 115592976424788.28]\n",
      "R2: [0.08283070051992217, 0.23456601106785016, 0.33346870100809894, 0.367164370990714]\n",
      "RMSE: [0.8462401326368166, 0.704619547738372, 0.6110292735429359, 0.5823978261909105]\n",
      "Training Ridge...\n",
      "Training Ridge with 7 days...\n",
      "Ridge trained!\n",
      "MAPE: [80199974870099.66]\n",
      "R2: [0.05274932260140909]\n",
      "RMSE: [1.065638871999733]\n",
      "Training Ridge with 14 days...\n",
      "Ridge trained!\n",
      "MAPE: [80199974870099.66, 73375182454305.6]\n",
      "R2: [0.05274932260140909, 0.45702171187075535]\n",
      "RMSE: [1.065638871999733, 0.5611914819484466]\n",
      "Training Ridge with 21 days...\n",
      "Ridge trained!\n",
      "MAPE: [80199974870099.66, 73375182454305.6, 66549914836640.19]\n",
      "R2: [0.05274932260140909, 0.45702171187075535, 0.01336771981694366]\n",
      "RMSE: [1.065638871999733, 0.5611914819484466, 0.7194884036617185]\n",
      "Training Ridge with 28 days...\n",
      "Ridge trained!\n",
      "MAPE: [80199974870099.66, 73375182454305.6, 66549914836640.19, 66643424435900.59]\n",
      "R2: [0.05274932260140909, 0.45702171187075535, 0.01336771981694366, 0.15791517738057215]\n",
      "RMSE: [1.065638871999733, 0.5611914819484466, 0.7194884036617185, 0.6619650549578425]\n",
      "Training Lasso...\n",
      "Training Lasso with 7 days...\n",
      "Lasso trained!\n",
      "MAPE: [74378838839515.5]\n",
      "R2: [0.12183153540335999]\n",
      "RMSE: [0.9470053589953064]\n",
      "Training Lasso with 14 days...\n",
      "Lasso trained!\n",
      "MAPE: [74378838839515.5, 71431795199399.72]\n",
      "R2: [0.12183153540335999, 0.5167132355339938]\n",
      "RMSE: [0.9470053589953064, 0.4715664348469726]\n",
      "Training Lasso with 21 days...\n",
      "Lasso trained!\n",
      "MAPE: [74378838839515.5, 71431795199399.72, 71167750238712.58]\n",
      "R2: [0.12183153540335999, 0.5167132355339938, 0.5508513599756621]\n",
      "RMSE: [0.9470053589953064, 0.4715664348469726, 0.40124047701184345]\n",
      "Training Lasso with 28 days...\n",
      "Lasso trained!\n",
      "MAPE: [74378838839515.5, 71431795199399.72, 71167750238712.58, 67227504097171.516]\n",
      "R2: [0.12183153540335999, 0.5167132355339938, 0.5508513599756621, 0.27375066653110464]\n",
      "RMSE: [0.9470053589953064, 0.4715664348469726, 0.40124047701184345, 0.58323813416684]\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store the trained models\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "trained_models = []\n",
    "\n",
    "# Iterate over each model and train them\n",
    "for model in model_dict.keys():\n",
    "    print(f'Training {model}...')\n",
    "    \n",
    "    # Create a pipeline with a scaler and the model\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('model', model_dict[model]['model'])])\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "    r2_scores = []\n",
    "    # Iterate over the sliding window\n",
    "    for n_days in number_of_days:\n",
    "        model_tmp = model_dict[model]['model']\n",
    "        if(best_params[model] != []):\n",
    "            model_tmp.set_params(**best_params[model][number_of_days.index(n_days)])\n",
    "        pipeline = Pipeline([('scaler', StandardScaler()), ('model', model_dict[model]['model'])])\n",
    "        print(f'Training {model} with {n_days} days...')\n",
    "        for i in range(0,dfWind.shape[0] - (n_days + 1)*24, 24):\n",
    "            # Get the training data\n",
    "            X_train = dfWind.iloc[i:i+n_days*24].drop(['Velocidad horario del viento (m/s)', 'Fecha'], axis=1)\n",
    "            y_train = dfWind.iloc[i:i+n_days*24]['Velocidad horario del viento (m/s)']            \n",
    "            # Fit the model\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            #print(f'Window {i+1}-{i+7}: Model fitted!')\n",
    "            # Validate the model\n",
    "            X_valid = dfWind.iloc[i+n_days*24:i+((n_days + 1)*24)].drop(['Velocidad horario del viento (m/s)', 'Fecha'], axis=1)\n",
    "            y_valid = dfWind.iloc[i+n_days*24:i+((n_days + 1)*24)]['Velocidad horario del viento (m/s)']\n",
    "            score = pipeline.score(X_valid, y_valid)\n",
    "            y_true = y_valid\n",
    "            y_pred = pipeline.predict(X_valid)\n",
    "            rmse_score = mean_squared_error(y_true, y_pred)\n",
    "            mape_score = mean_absolute_percentage_error(y_true, y_pred)\n",
    "            r2_score_tmp = r2_score(y_true, y_pred)\n",
    "            rmse_scores.append(rmse_score)\n",
    "            mape_scores.append(mape_score)\n",
    "            r2_scores.append(r2_score_tmp)\n",
    "            #print(f'Window {i}-{i+6}: Score = {score}') \n",
    "        # Save the scores\n",
    "        model_dict[model]['MAPE_score'].append(np.mean(mape_scores))\n",
    "        model_dict[model]['R2_score'].append(np.mean(r2_scores))\n",
    "        model_dict[model]['RMSE_score'].append(np.mean(rmse_scores))\n",
    "        rmse_scores = []\n",
    "        mape_scores = []\n",
    "        r2_scores = []\n",
    "        trained_models.append(pipeline)\n",
    "        print(f'{model} trained!')\n",
    "        print(f'MAPE: {model_dict[model][\"MAPE_score\"]}')\n",
    "        print(f'R2: {model_dict[model][\"R2_score\"]}')\n",
    "        print(f'RMSE: {model_dict[model][\"RMSE_score\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# File path to save the dictionary\n",
    "file_path = '../data/model_exo4_results.pkl'\n",
    "\n",
    "# Save the dictionary into a file\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(model_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree': {'model': DecisionTreeRegressor(max_depth=20, min_samples_split=0.1, random_state=42), 'grid': {'max_depth': (1, 20), 'min_samples_split': (0.1, 1.0)}, 'MAPE_score': [80200798239406.03, 88711873783999.02, 103043452094794.83, 72295978716041.75], 'R2_score': [0.362329532114189, 0.47364411826624664, 0.4479596262008063, 0.5034122717854398], 'RMSE_score': [0.5812604669144814, 0.4817635708201701, 0.5004075012333904, 0.4457925095100728]}, 'Random Forest': {'model': RandomForestRegressor(max_depth=6, n_estimators=200, random_state=42), 'grid': {'max_depth': (1, 20), 'n_estimators': [100, 200, 300]}, 'n_estimators': range(1, 20), 'MAPE_score': [81607234341902.56, 73368485888530.53, 77910419980004.86, 67906817030324.336], 'R2_score': [0.5446504505277066, 0.5870522624137625, 0.5645065018813064, 0.6072123010567742], 'RMSE_score': [0.4217273773627547, 0.38262266359355546, 0.3981726840078157, 0.36327904126460725]}, 'Gradient Boosting': {'model': GradientBoostingRegressor(min_samples_split=0.7988052095783587, random_state=42), 'grid': {'max_depth': (1, 20), 'min_samples_split': (0.1, 1.0)}, 'MAPE_score': [82003114542011.16, 85131749820761.67, 84421806169916.22, 74488197785733.05], 'R2_score': [0.524809721228212, 0.5773859178516063, 0.5910344481794995, 0.6070234312123858], 'RMSE_score': [0.4411063483970683, 0.3909666440258513, 0.3771596829807505, 0.3630620006776562]}, 'Knn': {'model': KNeighborsRegressor(n_neighbors=16), 'grid': {'n_neighbors': (1, 20)}, 'MAPE_score': [142360027014206.3, 129573827181546.03, 117461717368969.97, 115592976424788.28], 'R2_score': [0.08283070051992217, 0.23456601106785016, 0.33346870100809894, 0.367164370990714], 'RMSE_score': [0.8462401326368166, 0.704619547738372, 0.6110292735429359, 0.5823978261909105]}, 'Ridge': {'model': Ridge(alpha=0.1), 'grid': {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, 'MAPE_score': [80199974870099.66, 73375182454305.6, 66549914836640.19, 66643424435900.59], 'R2_score': [0.05274932260140909, 0.45702171187075535, 0.01336771981694366, 0.15791517738057215], 'RMSE_score': [1.065638871999733, 0.5611914819484466, 0.7194884036617185, 0.6619650549578425]}, 'Lasso': {'model': Lasso(alpha=0.001), 'grid': {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, 'MAPE_score': [74378838839515.5, 71431795199399.72, 71167750238712.58, 67227504097171.516], 'R2_score': [0.12183153540335999, 0.5167132355339938, 0.5508513599756621, 0.27375066653110464], 'RMSE_score': [0.9470053589953064, 0.4715664348469726, 0.40124047701184345, 0.58323813416684]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the path to the pickle file\n",
    "file_path = '../data/model_exo4_results.pkl'\n",
    "\n",
    "# Open the pickle file in read mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    # Load the dictionary from the pickle file\n",
    "    dictionary = pickle.load(file)\n",
    "\n",
    "# Now you can use the dictionary\n",
    "print(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_scores = []\n",
    "model_names = []\n",
    "list_r2 = []\n",
    "list_mape = []\n",
    "list_rmse = []\n",
    "min_rmse = 1000\n",
    "for i in range(len(number_of_days)):\n",
    "    for model in model_dict.keys():\n",
    "        if(i == 0):\n",
    "            model_names.append(model)\n",
    "        list_r2.append(model_dict[model]['R2_score'][i])\n",
    "        list_mape.append(model_dict[model]['MAPE_score'][i])\n",
    "        list_rmse.append(model_dict[model]['RMSE_score'][i])\n",
    "        if(model_dict[model]['RMSE_score'][i] < min_rmse):\n",
    "            num_days = number_of_days[i]\n",
    "            min_rmse = model_dict[model]['RMSE_score'][i]\n",
    "            best_model = model\n",
    "    df_scores = pd.DataFrame({'Model': model_names, 'R2': list_r2, 'MAPE': list_mape, 'RMSE': list_rmse})\n",
    "    list_mape = []\n",
    "    list_r2 = []\n",
    "    list_rmse = []\n",
    "    list_df_scores.append(df_scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days: 7\n",
      "            Model       R2         MAPE     RMSE\n",
      "    Decision Tree 0.362330 8.020080e+13 0.581260\n",
      "    Random Forest 0.544650 8.160723e+13 0.421727\n",
      "Gradient Boosting 0.524810 8.200311e+13 0.441106\n",
      "              Knn 0.082831 1.423600e+14 0.846240\n",
      "            Ridge 0.052749 8.019997e+13 1.065639\n",
      "            Lasso 0.121832 7.437884e+13 0.947005\n",
      "Number of days: 14\n",
      "            Model       R2         MAPE     RMSE\n",
      "    Decision Tree 0.473644 8.871187e+13 0.481764\n",
      "    Random Forest 0.587052 7.336849e+13 0.382623\n",
      "Gradient Boosting 0.577386 8.513175e+13 0.390967\n",
      "              Knn 0.234566 1.295738e+14 0.704620\n",
      "            Ridge 0.457022 7.337518e+13 0.561191\n",
      "            Lasso 0.516713 7.143180e+13 0.471566\n",
      "Number of days: 21\n",
      "            Model       R2         MAPE     RMSE\n",
      "    Decision Tree 0.447960 1.030435e+14 0.500408\n",
      "    Random Forest 0.564507 7.791042e+13 0.398173\n",
      "Gradient Boosting 0.591034 8.442181e+13 0.377160\n",
      "              Knn 0.333469 1.174617e+14 0.611029\n",
      "            Ridge 0.013368 6.654991e+13 0.719488\n",
      "            Lasso 0.550851 7.116775e+13 0.401240\n",
      "Number of days: 28\n",
      "            Model       R2         MAPE     RMSE\n",
      "    Decision Tree 0.503412 7.229598e+13 0.445793\n",
      "    Random Forest 0.607212 6.790682e+13 0.363279\n",
      "Gradient Boosting 0.607023 7.448820e+13 0.363062\n",
      "              Knn 0.367164 1.155930e+14 0.582398\n",
      "            Ridge 0.157915 6.664342e+13 0.661965\n",
      "            Lasso 0.273751 6.722750e+13 0.583238\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(number_of_days)):\n",
    "    print(f'Number of days: {number_of_days[i]}')\n",
    "    print(list_df_scores[i].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analize the RMSE results to find the best model and the best training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_scores = []\n",
    "list_rmse = []\n",
    "for i in range(len(number_of_days)):\n",
    "    for model in model_dict.keys():  \n",
    "        list_rmse.append(model_dict[model]['RMSE_score'][i])\n",
    "    name = 'RMSE_' + str(number_of_days[i])\n",
    "    if i == 0:\n",
    "        df_scores = pd.DataFrame({'Model': model_names, name: list_rmse})\n",
    "    else:\n",
    "        df_scores = pd.DataFrame({name: list_rmse})\n",
    "    list_df_scores.append(df_scores)\n",
    "    list_rmse = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE_7</th>\n",
       "      <th>RMSE_14</th>\n",
       "      <th>RMSE_21</th>\n",
       "      <th>RMSE_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.581260</td>\n",
       "      <td>0.481764</td>\n",
       "      <td>0.500408</td>\n",
       "      <td>0.445793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.421727</td>\n",
       "      <td>0.382623</td>\n",
       "      <td>0.398173</td>\n",
       "      <td>0.363279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.441106</td>\n",
       "      <td>0.390967</td>\n",
       "      <td>0.377160</td>\n",
       "      <td>0.363062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Knn</td>\n",
       "      <td>0.846240</td>\n",
       "      <td>0.704620</td>\n",
       "      <td>0.611029</td>\n",
       "      <td>0.582398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.065639</td>\n",
       "      <td>0.561191</td>\n",
       "      <td>0.719488</td>\n",
       "      <td>0.661965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.947005</td>\n",
       "      <td>0.471566</td>\n",
       "      <td>0.401240</td>\n",
       "      <td>0.583238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model    RMSE_7   RMSE_14   RMSE_21   RMSE_28\n",
       "0      Decision Tree  0.581260  0.481764  0.500408  0.445793\n",
       "1      Random Forest  0.421727  0.382623  0.398173  0.363279\n",
       "2  Gradient Boosting  0.441106  0.390967  0.377160  0.363062\n",
       "3                Knn  0.846240  0.704620  0.611029  0.582398\n",
       "4              Ridge  1.065639  0.561191  0.719488  0.661965\n",
       "5              Lasso  0.947005  0.471566  0.401240  0.583238"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.concat(list_df_scores, axis=1)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is Gradient Boosting with a RMSE of 0.3630620006776562, and 28 days of training\n"
     ]
    }
   ],
   "source": [
    "print(f'The best model is {best_model} with a RMSE of {min_rmse}, and {num_days} days of training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "BayesianOptimization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}